# -*- coding: utf-8 -*-
"""yolo_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N5fcksJC50Q1KvalWLoD3_bq-tn7M-2o

Clone the Github Repository and mount the Google Drive

Also enable GPU in Edit--> Notebook setting--> Hardware accelerator --> GPU
"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# git clone https://github.com/ansarisam/darknet.git

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# #rm -r /content/darknet

"""Download the Make file in darknet folder and replace gpu=1 and opencv=1 and upload back to same location in darknet folder."""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cd darknet/
# make

"""Download the pre-trained weights to initialize the training"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cd /content/pretrained
# wget https://pjreddie.com/media/files/darknet53.conv.74



"""Copy the train and test images from drive to colab environment to the exact location specified below"""

!cp -r /content/drive/My\ Drive/Capstone/train_images/*.jpg /content/data/train_images

!cp -r /content/drive/My\ Drive/Capstone/test_images/*.jpg /content/data/test_images

#%cd /content

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/'My Drive'/Capstone/computer_vision/models/research

!pwd

import io
import os
from lxml import etree
from object_detection.utils import dataset_util
import tensorflow as tf



tf.test.gpu_device_name()

"""Create train.txt and test.txt files which has absolute location to images in colab environment"""

#train
train = open("/content/data/train.txt",'w')
for file in os.listdir("/content/drive/My Drive/Capstone/train_images"):
  train.write(os.path.join("/content/data/images/",file))
  train.write("\n")
train.close()

#test
test = open("/content/data/test.txt",'w')
for file in os.listdir("/content/drive/My Drive/Capstone/test_images"):
  test.write(os.path.join("/content/data/images/",file))
  test.write("\n")
test.close()



#!cp /content/data/train.txt /content/drive/My\ Drive/Capstone/

#!cp /content/data/test.txt /content/drive/My\ Drive/Capstone/

"""Function to convert XML to txt format"""

def xml_to_csv(annotations,def_class,in_path,out_path):
  count = 0 
  for idx,annot in enumerate(annotations):
    if annot.endswith('.xml'):
      path = os.path.join(in_path, annot)
      with tf.io.gfile.GFile(path, 'r') as fid:
        xml_str = fid.read()
      xml = etree.fromstring(xml_str)
      groundtruth_data = dataset_util.recursive_parse_xml_to_dict(xml)['annotation']
      h = int(groundtruth_data['size']['height'])  
      w = int(groundtruth_data['size']['width'])
      if '.jpg' in groundtruth_data['filename']:
        filename = groundtruth_data['filename']
        filename = filename.replace('.jpg','')
        filename = filename+'.txt'
      else:
        filename = groundtruth_data['filename']
        filename = filename+'.txt'
      num_annotations_skipped = 0
      write_file = open(out_path+filename,'w')
      #write_file.write("Class,x_center,y_centre,Width,Height")
      #write_file.write("\n")
      for objects in groundtruth_data['object']:
        defect = def_class[objects['name']]
        xmi = int(objects['bndbox']['xmin'])
        ymi = int(objects['bndbox']['ymin'])
        xma = int(objects['bndbox']['xmax'])
        yma = int(objects['bndbox']['ymax'])
        if xma <= 0 or yma <= 0:
          num_annotations_skipped += 1
          continue
        if xma > w or yma > h:
          num_annotations_skipped += 1
          continue
        x = float(((xmi+xma)/2) - 1)
        y = float(((ymi+yma)/2) - 1)
        xo = float(x/w)
        yo = float(y/h)
        ho = float((yma-ymi)/h)
        wo = float((xma-xmi)/w)
        write_file.write("%d %f %f %f %f"%(defect,xo,yo,wo,ho))
        write_file.write("\n")
      count += 1
      print("Total files written = ",count)
      print("Total annotations skipped = ",num_annotations_skipped)
      write_file.close()

defect = open('/content/drive/My Drive/Capstone/class.data','r')
defect_cls = defect.read()
defect_cls = defect_cls.split('\n')
defect_cls

dict_class = {defect_cls[i]:i for i in range(0,len(defect_cls))}
dict_class

dict_class.values()

"""Converting train xml files to txt"""

train_path = '/content/drive/My Drive/Capstone/train_annotations/'
train_out = '/content/data/annotations/train/'
train_annot = os.listdir(train_path)
xml_to_csv(train_annot,dict_class,train_path,train_out)

"""Converting test xml files to txt"""

test_path = '/content/drive/My Drive/Capstone/test_annotations/'
test_out = '/content/data/annotations/test/'
test_annot = os.listdir(test_path)
xml_to_csv(test_annot,dict_class,test_path,test_out)



"""Copy all the txt files to location in drive to avoid creating txt files every time the runtime gets disconnected"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# #cp -r  /content/data/annotations/train/*.txt /content/drive/My\ Drive/Capstone/annotations/train/

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# #cp /content/data/annotations/test/*.txt /content/drive/My\ Drive/Capstone/annotations/test/

"""NOTE: Creating the txt files and copying them to drive has to be done only once, i.e when you run this code for first time. From the second time we can simply copy the txt files from drive to colab as shown below

Copying the txt files from drive to colab environment to specific location below
"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cp -r /content/drive/My\ Drive/Capstone/annotations/train/*.txt /content/data/annotations/train/

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cp /content/drive/My\ Drive/Capstone/annotations/test/*.txt /content/data/annotations/test/



"""Create a labels folder in data and copy att the txt files of train and test into it"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cp /content/data/annotations/train/*.txt /content/data/labels

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cp /content/data/annotations/test/*.txt /content/data/labels

"""Create images folder inside data and copy all the images both train and test into that folder"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cp /content/data/train_images/*.jpg /content/data/images

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cp /content/data/test_images/*.jpg /content/data/images

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!pwd

"""All train.txt, text.txt, class.data needs to be unix formatted files so we need to convert them from dos2unix as shown below"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# sudo apt install dos2unix

"""Linking backupfolder in Drive to colab environment"""

!ln -s /content/drive/My\ Drive/Capstone/backup /content/yolov3_folder

!ls /content/yolov3_folder

"""Converting required files into dos2unix"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# dos2unix /content/input.cfg
# dos2unix /content/data/class.data

"""Training the Model"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell 
# cd /content/darknet
# ./darknet detector train /content/input.cfg /content/yolov3-voc.cfg /content/yolov3_folder/yolov3-voc.backup





"""Testing on Single image"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cd /content/darknet
# ./darknet detector test /content/input.cfg /content/yolov3-voc.cfg /content/yolov3_folder/yolov3-voc_18000.weights /content/data/test_images/crazing_204.jpg

#!rm -rf /content/darknet

#!rm -r /content/output

"""Testing on all the test images

We need to upload specific python code into darknet folder for generating predictions in json format
"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cd /content/darknet/
# python Text_worked.py



"""Copying all the outputs to Drive"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cp  /content/output/*.json /content/drive/My\ Drive/Capstone/predictions/







# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cd /content/darknet/
# python Text_rough.py

#%%shell
#rm -r /content/data/test_images/.ipynb_checkpoints



"""Bounding Box predictions with images"""

import cv2,os,json
from google.colab.patches import cv2_imshow

"""Predicted"""

color=(0,0,255)
thickness=1
for files in os.listdir('/content/drive/My Drive/Capstone/predictions/'):
  with open("/content/drive/My Drive/Capstone/predictions/"+files, 'r') as f:
    test_json = json.load(f)
  if len(test_json) == 0:
    continue
  else:
    print(test_json[0]['image'])
    path=test_json[0]['image']
    img=cv2.imread(path)
    for i in range(0,len(test_json)):
      a=test_json[i]['predictions']['bbox']
      start=(int(a[0]),int(a[1]))
      end=(int(a[2]),int(a[3]))
      x=int(a[0])
      if int(a[1]) > 5:
        y=int(a[1])-1
      else:
        y=int(a[1])+13
      predictedimg=cv2.rectangle(img,start,end,color,thickness)
      predictedimg=cv2.putText(predictedimg,test_json[i]['predictions']['object']+':'+test_json[i]['predictions']['score'],(x,y),cv2.FONT_HERSHEY_PLAIN,1,color,1,cv2.LINE_AA)
    cv2_imshow(predictedimg)

"""Actual"""

color=(255,0,0)
thickness=1
test_path = '/content/drive/My Drive/Capstone/test_annotations/'
#test_out = '/content/data/annotations/test/'
annotations = os.listdir(test_path)
for idx,annot in enumerate(annotations):
    if annot.endswith('.xml'):
      path = os.path.join(test_path, annot)
      with tf.io.gfile.GFile(path, 'r') as fid:
        xml_str = fid.read()
      xml = etree.fromstring(xml_str)
      groundtruth_data = dataset_util.recursive_parse_xml_to_dict(xml)['annotation']
      annot = annot.replace('.xml','.jpg')
      path = '/content/data/test_images/'+annot
      print(path)
      img=cv2.imread(path)
      for objects in groundtruth_data['object']:
        defect = objects['name']
        xmi = int(objects['bndbox']['xmin'])
        ymi = int(objects['bndbox']['ymin'])
        xma = int(objects['bndbox']['xmax'])
        yma = int(objects['bndbox']['ymax'])
        start=(xmi,ymi)
        end=(xma,yma)
        x=xmi
        if ymi > 5:
          y=ymi-1
        else:
          y=ymi+13
        predictedimg=cv2.rectangle(img,start,end,color,thickness)
        predictedimg=cv2.putText(predictedimg,defect,(x,y),cv2.FONT_HERSHEY_PLAIN,1,color,1,cv2.LINE_AA)
      cv2_imshow(predictedimg)



"""For measuring the performance of the model we need to delete previous darknet directory and clone alexAB darknet repository"""

!rm -r /content/darknet

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# git clone https://github.com/AlexeyAB/darknet

"""Make similar changes in make file and upload it back"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cd darknet/
# make

"""This repositry requires all images and lables to be in images directory so copy all labels to images directory"""

!cp /content/data/labels/*.txt /content/data/images

"""Claculating mAP, Precision, Recall and F1-score of the model"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cd /content/darknet
# ./darknet detector map /content/input.cfg /content/yolov3-voc.cfg /content/drive/My\ Drive/Capstone/yolo_steel_defect_final_weights/yolov3-voc_12000.weights

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# cd /content/darknet
# ./darknet detector calc_anchors /content/input.cfg -num_of_clusters 9 -width 416 -height 416
